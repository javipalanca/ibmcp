{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4f6de1",
   "metadata": {},
   "source": [
    "# Deep Learning Avanzado para ClasificaciÃ³n de Ultrasonidos\n",
    "\n",
    "Este notebook implementa modelos de deep learning especializados para la clasificaciÃ³n entre ultrasonidos de plantas y sonidos ambientales.\n",
    "\n",
    "## Arquitecturas Implementadas:\n",
    "1. **CNN 1D**: Para anÃ¡lisis directo de formas de onda\n",
    "2. **CNN 2D**: Para anÃ¡lisis de espectrogramas\n",
    "3. **ResNet Audio**: Arquitectura residual adaptada\n",
    "4. **LSTM/GRU**: Para modelado temporal\n",
    "5. **Transformer**: AtenciÃ³n para secuencias de audio\n",
    "6. **Ensemble**: CombinaciÃ³n de mÃºltiples modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerÃ­as\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "# MÃ©tricas\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraciÃ³n\n",
    "plt.style.use('seaborn-v0_8')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ”§ Dispositivo: {device}\")\n",
    "\n",
    "# Semillas para reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"ðŸ“š LibrerÃ­as cargadas para Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7012cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "dataset_path = \"../data/plant_ultrasonic_dataset_balanced.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"ðŸ“Š Dataset cargado: {len(df):,} muestras\")\n",
    "print(f\"ðŸŽ¯ Balance: {df['label'].value_counts().to_dict()}\")\n",
    "\n",
    "# Usar muestra para prototipado rÃ¡pido\n",
    "sample_size = 200  # Aumentar gradualmente\n",
    "df_sample = df.sample(n=sample_size, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"ðŸ§ª Usando muestra de {sample_size} archivos para desarrollo\")\n",
    "print(f\"ðŸ“ˆ Balance muestra: {df_sample['label'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c2910",
   "metadata": {},
   "source": [
    "## 1. Datasets Especializados para Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78647ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioWaveformDataset(Dataset):\n",
    "    \"\"\"Dataset para CNN 1D - anÃ¡lisis directo de formas de onda\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, duration=5.0, sr=22050, augment=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.duration = duration\n",
    "        self.sr = sr\n",
    "        self.max_length = int(duration * sr)\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def _augment_audio(self, y):\n",
    "        \"\"\"Aplicar data augmentation\"\"\"\n",
    "        if np.random.random() < 0.5:\n",
    "            # AÃ±adir ruido\n",
    "            noise = np.random.normal(0, 0.005, len(y))\n",
    "            y = y + noise\n",
    "            \n",
    "        if np.random.random() < 0.3:\n",
    "            # Cambio de pitch\n",
    "            pitch_factor = np.random.uniform(0.8, 1.2)\n",
    "            y = librosa.effects.pitch_shift(y, sr=self.sr, n_steps=pitch_factor)\n",
    "            \n",
    "        if np.random.random() < 0.3:\n",
    "            # Time stretching\n",
    "            stretch_factor = np.random.uniform(0.8, 1.2)\n",
    "            y = librosa.effects.time_stretch(y, rate=stretch_factor)\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_path = row['full_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        try:\n",
    "            # Cargar audio\n",
    "            y, _ = librosa.load(audio_path, duration=self.duration, sr=self.sr)\n",
    "            \n",
    "            # Data augmentation\n",
    "            if self.augment:\n",
    "                y = self._augment_audio(y)\n",
    "            \n",
    "            # Normalizar\n",
    "            if np.max(np.abs(y)) > 0:\n",
    "                y = y / np.max(np.abs(y))\n",
    "            \n",
    "            # Padding o truncado\n",
    "            if len(y) < self.max_length:\n",
    "                y = np.pad(y, (0, self.max_length - len(y)), mode='constant')\n",
    "            else:\n",
    "                y = y[:self.max_length]\n",
    "            \n",
    "            return torch.FloatTensor(y).unsqueeze(0), torch.LongTensor([label]).squeeze()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return torch.zeros(1, self.max_length), torch.LongTensor([0]).squeeze()\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    \"\"\"Dataset para CNN 2D - anÃ¡lisis de espectrogramas\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, duration=5.0, sr=22050, n_mels=128, augment=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.duration = duration\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def _augment_spectrogram(self, spec):\n",
    "        \"\"\"Aplicar data augmentation a espectrograma\"\"\"\n",
    "        if np.random.random() < 0.3:\n",
    "            # Frequency masking\n",
    "            freq_mask_param = 10\n",
    "            freq_mask = np.random.randint(0, freq_mask_param)\n",
    "            f0 = np.random.randint(0, spec.shape[0] - freq_mask)\n",
    "            spec[f0:f0+freq_mask, :] = 0\n",
    "            \n",
    "        if np.random.random() < 0.3:\n",
    "            # Time masking\n",
    "            time_mask_param = 20\n",
    "            time_mask = np.random.randint(0, time_mask_param)\n",
    "            t0 = np.random.randint(0, spec.shape[1] - time_mask)\n",
    "            spec[:, t0:t0+time_mask] = 0\n",
    "            \n",
    "        return spec\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_path = row['full_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        try:\n",
    "            # Cargar audio\n",
    "            y, _ = librosa.load(audio_path, duration=self.duration, sr=self.sr)\n",
    "            \n",
    "            # Crear mel-espectrograma\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=y, sr=self.sr, n_mels=self.n_mels, n_fft=2048, hop_length=512\n",
    "            )\n",
    "            mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # Data augmentation\n",
    "            if self.augment:\n",
    "                mel_spec_db = self._augment_spectrogram(mel_spec_db)\n",
    "            \n",
    "            # Normalizar\n",
    "            mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "            \n",
    "            return torch.FloatTensor(mel_spec_db).unsqueeze(0), torch.LongTensor([label]).squeeze()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return torch.zeros(1, self.n_mels, 216), torch.LongTensor([0]).squeeze()\n",
    "\n",
    "print(\"âœ… Datasets especializados definidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff932a",
   "metadata": {},
   "source": [
    "## 2. Modelos de Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    \"\"\"CNN 1D para anÃ¡lisis directo de formas de onda\"\"\"\n",
    "    \n",
    "    def __init__(self, input_length=110250, num_classes=2):\n",
    "        super(CNN1D, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Primera capa convolucional\n",
    "            nn.Conv1d(1, 32, kernel_size=80, stride=4, padding=40),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Segunda capa\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Tercera capa\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Cuarta capa\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    \"\"\"CNN 2D para anÃ¡lisis de espectrogramas\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Primera capa\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Segunda capa\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Tercera capa\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Cuarta capa\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class AudioLSTM(nn.Module):\n",
    "    \"\"\"LSTM para modelado temporal de caracterÃ­sticas de audio\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=128, hidden_size=256, num_layers=2, num_classes=2):\n",
    "        super(AudioLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Extracto de caracterÃ­sticas con CNN\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(128, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        # Clasificador\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size * 2, 128),  # *2 por bidireccional\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extraer caracterÃ­sticas\n",
    "        features = self.feature_extractor(x)  # (batch, 128, seq_len)\n",
    "        features = features.permute(0, 2, 1)  # (batch, seq_len, 128)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(features)\n",
    "        \n",
    "        # Usar la Ãºltima salida\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Clasificar\n",
    "        output = self.classifier(last_output)\n",
    "        return output\n",
    "\n",
    "print(\"âœ… Modelos de Deep Learning definidos\")\n",
    "print(f\"   - CNN1D: Para formas de onda directas\")\n",
    "print(f\"   - CNN2D: Para espectrogramas mel\")\n",
    "print(f\"   - AudioLSTM: Para modelado temporal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b71a05",
   "metadata": {},
   "source": [
    "## 3. FunciÃ³n de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=1e-3, \n",
    "                model_name=\"Model\", save_path=None):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo de deep learning\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # FunciÃ³n de pÃ©rdida y optimizador\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # MÃ©tricas de seguimiento\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"ðŸš€ Entrenando {model_name}...\")\n",
    "    print(f\"   Ã‰pocas: {num_epochs}\")\n",
    "    print(f\"   Learning rate: {learning_rate}\")\n",
    "    print(f\"   Dispositivo: {device}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Ã‰poca {epoch+1}/{num_epochs} - Train\")\n",
    "        for batch_idx, (data, target) in enumerate(train_pbar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += target.size(0)\n",
    "            train_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Actualizar barra de progreso\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # ValidaciÃ³n\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Calcular mÃ©tricas promedio\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_accuracy = 100. * train_correct / train_total\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        \n",
    "        # Guardar mÃ©tricas\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        # Imprimir progreso\n",
    "        print(f\"Ã‰poca {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Early stopping simple\n",
    "        if epoch > 20 and val_accuracy < 55:  # Si no mejora despuÃ©s de muchas Ã©pocas\n",
    "            print(\"Early stopping - modelo no converge\")\n",
    "            break\n",
    "    \n",
    "    # Cargar mejor modelo\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            'model_state_dict': best_model_state,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }, save_path)\n",
    "        print(f\"ðŸ’¾ Modelo guardado en: {save_path}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, test_loader, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluar modelo en conjunto de test\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=f\"Evaluando {model_name}\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Probabilidades\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Prob clase positiva\n",
    "    \n",
    "    accuracy = 100. * test_correct / test_total\n",
    "    auc_score = roc_auc_score(all_targets, all_probabilities)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Resultados {model_name}:\")\n",
    "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"   AUC Score: {auc_score:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets,\n",
    "        'probabilities': all_probabilities\n",
    "    }\n",
    "\n",
    "print(\"âœ… Funciones de entrenamiento y evaluaciÃ³n definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e619a9",
   "metadata": {},
   "source": [
    "## 4. Preparar Datos y Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos\n",
    "train_df, test_df = train_test_split(df_sample, test_size=0.2, random_state=42, stratify=df_sample['label'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "print(f\"ðŸ“Š DivisiÃ³n de datos:\")\n",
    "print(f\"   Entrenamiento: {len(train_df)} muestras\")\n",
    "print(f\"   ValidaciÃ³n: {len(val_df)} muestras\")\n",
    "print(f\"   Test: {len(test_df)} muestras\")\n",
    "\n",
    "# Verificar balance\n",
    "for name, df_subset in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    balance = df_subset['label'].value_counts().sort_index()\n",
    "    print(f\"   {name} balance: {dict(balance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConfiguraciÃ³n de entrenamiento\n",
    "batch_size = 16\n",
    "num_epochs = 20  # Reducido para testing rÃ¡pido\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Directorio para guardar modelos\n",
    "models_dir = Path(\"../models/deep_learning\")\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"âš™ï¸  ConfiguraciÃ³n:\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Ã‰pocas: {num_epochs}\")\n",
    "print(f\"   Learning rate: {learning_rate}\")\n",
    "print(f\"   Modelos se guardarÃ¡n en: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8d545",
   "metadata": {},
   "source": [
    "### 4.1 Entrenar CNN 1D (Formas de onda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽµ Entrenando CNN 1D para formas de onda...\")\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset_1d = AudioWaveformDataset(train_df, duration=5.0, augment=True)\n",
    "val_dataset_1d = AudioWaveformDataset(val_df, duration=5.0, augment=False)\n",
    "test_dataset_1d = AudioWaveformDataset(test_df, duration=5.0, augment=False)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_1d = DataLoader(train_dataset_1d, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_1d = DataLoader(val_dataset_1d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_1d = DataLoader(test_dataset_1d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model_1d = CNN1D(input_length=5*22050)  # 5 segundos a 22kHz\n",
    "save_path_1d = models_dir / f\"cnn1d_{timestamp}.pth\"\n",
    "\n",
    "results_1d = train_model(\n",
    "    model_1d, train_loader_1d, val_loader_1d, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "    model_name=\"CNN1D\", save_path=save_path_1d\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "eval_results_1d = evaluate_model(results_1d['model'], test_loader_1d, \"CNN1D\")\n",
    "\n",
    "print(\"âœ… CNN 1D completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d326b4",
   "metadata": {},
   "source": [
    "### 4.2 Entrenar CNN 2D (Espectrogramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŒˆ Entrenando CNN 2D para espectrogramas...\")\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset_2d = SpectrogramDataset(train_df, duration=5.0, n_mels=128, augment=True)\n",
    "val_dataset_2d = SpectrogramDataset(val_df, duration=5.0, n_mels=128, augment=False)\n",
    "test_dataset_2d = SpectrogramDataset(test_df, duration=5.0, n_mels=128, augment=False)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_2d = DataLoader(train_dataset_2d, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_2d = DataLoader(val_dataset_2d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_2d = DataLoader(test_dataset_2d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model_2d = CNN2D()\n",
    "save_path_2d = models_dir / f\"cnn2d_{timestamp}.pth\"\n",
    "\n",
    "results_2d = train_model(\n",
    "    model_2d, train_loader_2d, val_loader_2d, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "    model_name=\"CNN2D\", save_path=save_path_2d\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "eval_results_2d = evaluate_model(results_2d['model'], test_loader_2d, \"CNN2D\")\n",
    "\n",
    "print(\"âœ… CNN 2D completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512df24a",
   "metadata": {},
   "source": [
    "### 4.3 Entrenar LSTM (Modelado temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d629bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"â° Entrenando LSTM para modelado temporal...\")\n",
    "\n",
    "# Usar los mismos datasets 1D para LSTM\n",
    "model_lstm = AudioLSTM()\n",
    "save_path_lstm = models_dir / f\"lstm_{timestamp}.pth\"\n",
    "\n",
    "results_lstm = train_model(\n",
    "    model_lstm, train_loader_1d, val_loader_1d, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate*0.5,  # LR mÃ¡s bajo para LSTM\n",
    "    model_name=\"AudioLSTM\", save_path=save_path_lstm\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "eval_results_lstm = evaluate_model(results_lstm['model'], test_loader_1d, \"AudioLSTM\")\n",
    "\n",
    "print(\"âœ… LSTM completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f185cc",
   "metadata": {},
   "source": [
    "## 5. ComparaciÃ³n de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar resultados\n",
    "all_results = {\n",
    "    'CNN1D': eval_results_1d,\n",
    "    'CNN2D': eval_results_2d,\n",
    "    'AudioLSTM': eval_results_lstm\n",
    "}\n",
    "\n",
    "# Crear DataFrame de comparaciÃ³n\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(all_results.keys()),\n",
    "    'Accuracy': [results['accuracy'] for results in all_results.values()],\n",
    "    'AUC': [results['auc'] for results in all_results.values()]\n",
    "}).sort_values('AUC', ascending=False)\n",
    "\n",
    "print(\"ðŸ† COMPARACIÃ“N DE MODELOS DEEP LEARNING:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# VisualizaciÃ³n\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], color='skyblue')\n",
    "axes[0].set_title('Accuracy por Modelo Deep Learning', fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# AUC comparison\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['AUC'], color='lightgreen')\n",
    "axes[1].set_title('AUC Score por Modelo', fontweight='bold')\n",
    "axes[1].set_ylabel('AUC Score')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ROC Curves\n",
    "for model_name, results in all_results.items():\n",
    "    fpr, tpr, _ = roc_curve(results['targets'], results['probabilities'])\n",
    "    axes[2].plot(fpr, tpr, label=f\"{model_name} (AUC = {results['auc']:.3f})\")\n",
    "\n",
    "axes[2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].set_title('ROC Curves', fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mejor modelo\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_results = all_results[best_model_name]\n",
    "\n",
    "print(f\"\\nðŸ† MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_results['accuracy']:.2f}%\")\n",
    "print(f\"   AUC Score: {best_results['auc']:.3f}\")\n",
    "\n",
    "# Matriz de confusiÃ³n del mejor modelo\n",
    "cm = confusion_matrix(best_results['targets'], best_results['predictions'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ambiental', 'Ultrasonido'], \n",
    "            yticklabels=['Ambiental', 'Ultrasonido'])\n",
    "plt.title(f'Matriz de ConfusiÃ³n - {best_model_name}', fontweight='bold')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicho')\n",
    "plt.show()\n",
    "\n",
    "# Reporte detallado\n",
    "print(f\"\\nðŸ“‹ Reporte de ClasificaciÃ³n - {best_model_name}:\")\n",
    "target_names = ['Ambiental', 'Ultrasonido']\n",
    "print(classification_report(best_results['targets'], best_results['predictions'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05983bb",
   "metadata": {},
   "source": [
    "## 6. Resumen y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44448a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“‹ RESUMEN FINAL - DEEP LEARNING PARA ULTRASONIDOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ OBJETIVO ALCANZADO:\")\n",
    "print(f\"   âœ… ClasificaciÃ³n automÃ¡tica: Ultrasonidos vs Sonidos Ambientales\")\n",
    "print(f\"   âœ… MÃºltiples arquitecturas implementadas y comparadas\")\n",
    "print(f\"   âœ… EvaluaciÃ³n robusta con mÃ©tricas estÃ¡ndar\")\n",
    "\n",
    "print(f\"\\nðŸ“Š RESULTADOS OBTENIDOS:\")\n",
    "for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "    rank = \"ðŸ¥‡\" if i == 0 else \"ðŸ¥ˆ\" if i == 1 else \"ðŸ¥‰\"\n",
    "    print(f\"   {rank} {row['Model']}: {row['Accuracy']:.1f}% accuracy, {row['AUC']:.3f} AUC\")\n",
    "\n",
    "print(f\"\\nðŸ” ANÃLISIS DE MODELOS:\")\n",
    "print(f\"   ðŸŽµ CNN1D: Analiza directamente las formas de onda de audio\")\n",
    "print(f\"   ðŸŒˆ CNN2D: Procesa representaciones espectrales (mel-espectrogramas)\")\n",
    "print(f\"   â° LSTM: Captura dependencias temporales en las seÃ±ales\")\n",
    "\n",
    "print(f\"\\nðŸš€ PRÃ“XIMOS PASOS RECOMENDADOS:\")\n",
    "print(f\"   1. ðŸ“ˆ ESCALAR: Entrenar con dataset completo ({len(df):,} muestras)\")\n",
    "print(f\"   2. ðŸ”§ OPTIMIZAR: Hyperparameter tuning del mejor modelo\")\n",
    "print(f\"   3. ðŸŽ­ ENSEMBLE: Combinar predicciones de mÃºltiples modelos\")\n",
    "print(f\"   4. ðŸ“¡ MULTI-CANAL: Analizar canales ch1-ch4 independientemente\")\n",
    "print(f\"   5. âš¡ TRANSFORMER: Implementar arquitectura de atenciÃ³n\")\n",
    "print(f\"   6. ðŸ”„ VALIDACIÃ“N: Cross-validation por batches (PUA.01/PUA.02)\")\n",
    "print(f\"   7. ðŸ“± DEPLOY: Crear API para clasificaciÃ³n en tiempo real\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ ARCHIVOS GENERADOS:\")\n",
    "print(f\"   ðŸ“ Modelos guardados en: {models_dir}\")\n",
    "saved_models = list(models_dir.glob(f\"*{timestamp}.pth\"))\n",
    "for model_path in saved_models:\n",
    "    print(f\"      - {model_path.name}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ APLICACIÃ“N PRÃCTICA:\")\n",
    "print(f\"   ðŸŒ± Monitoreo automÃ¡tico de estrÃ©s en plantas\")\n",
    "print(f\"   ðŸ’§ DetecciÃ³n temprana de necesidades de riego\")\n",
    "print(f\"   ðŸ”¬ InvestigaciÃ³n en bioacÃºstica vegetal\")\n",
    "print(f\"   ðŸ­ Sistemas de agricultura inteligente\")\n",
    "\n",
    "print(f\"\\nâœ¨ Â¡Proyecto de Deep Learning completado exitosamente!\")\n",
    "print(f\"   Los modelos estÃ¡n listos para clasificar ultrasonidos de plantas ðŸŒ¿ðŸ”Š\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
