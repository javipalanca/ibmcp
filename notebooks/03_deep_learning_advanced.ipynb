{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4f6de1",
   "metadata": {},
   "source": [
    "# Deep Learning Avanzado para Clasificación de Ultrasonidos\n",
    "\n",
    "Este notebook implementa modelos de deep learning especializados para la clasificación entre ultrasonidos de plantas y sonidos ambientales.\n",
    "\n",
    "## Arquitecturas Implementadas:\n",
    "1. **CNN 1D**: Para análisis directo de formas de onda\n",
    "2. **CNN 2D**: Para análisis de espectrogramas\n",
    "3. **ResNet Audio**: Arquitectura residual adaptada\n",
    "4. **LSTM/GRU**: Para modelado temporal\n",
    "5. **Transformer**: Atención para secuencias de audio\n",
    "6. **Ensemble**: Combinación de múltiples modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fec53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "import gc\n",
    "import math\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "# Métricas\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración\n",
    "plt.style.use('seaborn-v0_8')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"🔧 Dispositivo: {device}\")\n",
    "\n",
    "# Semillas para reproducibilidad\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(\"📚 Librerías cargadas para Deep Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7012cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "dataset_path = \"../data/plant_ultrasonic_dataset_balanced.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "print(f\"📊 Dataset cargado: {len(df):,} muestras\")\n",
    "print(f\"🎯 Balance: {df['label'].value_counts().to_dict()}\")\n",
    "\n",
    "# Usar muestra para prototipado rápido\n",
    "sample_size = 200  # Aumentar gradualmente\n",
    "df_sample = df.sample(n=sample_size, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"🧪 Usando muestra de {sample_size} archivos para desarrollo\")\n",
    "print(f\"📈 Balance muestra: {df_sample['label'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c2910",
   "metadata": {},
   "source": [
    "## 1. Datasets Especializados para Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78647ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioWaveformDataset(Dataset):\n",
    "    \"\"\"Dataset para CNN 1D - análisis directo de formas de onda\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, duration=5.0, sr=22050, augment=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.duration = duration\n",
    "        self.sr = sr\n",
    "        self.max_length = int(duration * sr)\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def _augment_audio(self, y):\n",
    "        \"\"\"Aplicar data augmentation\"\"\"\n",
    "        if np.random.random() < 0.5:\n",
    "            # Añadir ruido\n",
    "            noise = np.random.normal(0, 0.005, len(y))\n",
    "            y = y + noise\n",
    "            \n",
    "        if np.random.random() < 0.3:\n",
    "            # Cambio de pitch\n",
    "            pitch_factor = np.random.uniform(0.8, 1.2)\n",
    "            y = librosa.effects.pitch_shift(y, sr=self.sr, n_steps=pitch_factor)\n",
    "            \n",
    "        if np.random.random() < 0.3:\n",
    "            # Time stretching\n",
    "            stretch_factor = np.random.uniform(0.8, 1.2)\n",
    "            y = librosa.effects.time_stretch(y, rate=stretch_factor)\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_path = row['full_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        try:\n",
    "            # Cargar audio\n",
    "            y, _ = librosa.load(audio_path, duration=self.duration, sr=self.sr)\n",
    "            \n",
    "            # Data augmentation\n",
    "            if self.augment:\n",
    "                y = self._augment_audio(y)\n",
    "            \n",
    "            # Normalizar\n",
    "            if np.max(np.abs(y)) > 0:\n",
    "                y = y / np.max(np.abs(y))\n",
    "            \n",
    "            # Padding o truncado\n",
    "            if len(y) < self.max_length:\n",
    "                y = np.pad(y, (0, self.max_length - len(y)), mode='constant')\n",
    "            else:\n",
    "                y = y[:self.max_length]\n",
    "            \n",
    "            return torch.FloatTensor(y).unsqueeze(0), torch.LongTensor([label]).squeeze()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return torch.zeros(1, self.max_length), torch.LongTensor([0]).squeeze()\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    \"\"\"Dataset para CNN 2D - análisis de espectrogramas\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, duration=5.0, sr=22050, n_mels=128, augment=False):\n",
    "        self.dataframe = dataframe\n",
    "        self.duration = duration\n",
    "        self.sr = sr\n",
    "        self.n_mels = n_mels\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def _augment_spectrogram(self, spec):\n",
    "        \"\"\"Aplicar data augmentation a espectrograma\"\"\"\n",
    "        if np.random.random() < 0.3:\n",
    "            # Frequency masking\n",
    "            freq_mask_param = 10\n",
    "            freq_mask = np.random.randint(0, freq_mask_param)\n",
    "            f0 = np.random.randint(0, spec.shape[0] - freq_mask)\n",
    "            spec[f0:f0+freq_mask, :] = 0\n",
    "            \n",
    "        if np.random.random() < 0.3:\n",
    "            # Time masking\n",
    "            time_mask_param = 20\n",
    "            time_mask = np.random.randint(0, time_mask_param)\n",
    "            t0 = np.random.randint(0, spec.shape[1] - time_mask)\n",
    "            spec[:, t0:t0+time_mask] = 0\n",
    "            \n",
    "        return spec\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        audio_path = row['full_path']\n",
    "        label = row['label']\n",
    "        \n",
    "        try:\n",
    "            # Cargar audio\n",
    "            y, _ = librosa.load(audio_path, duration=self.duration, sr=self.sr)\n",
    "            \n",
    "            # Crear mel-espectrograma\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=y, sr=self.sr, n_mels=self.n_mels, n_fft=2048, hop_length=512\n",
    "            )\n",
    "            mel_spec_db = librosa.amplitude_to_db(mel_spec, ref=np.max)\n",
    "            \n",
    "            # Data augmentation\n",
    "            if self.augment:\n",
    "                mel_spec_db = self._augment_spectrogram(mel_spec_db)\n",
    "            \n",
    "            # Normalizar\n",
    "            mel_spec_db = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "            \n",
    "            return torch.FloatTensor(mel_spec_db).unsqueeze(0), torch.LongTensor([label]).squeeze()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return torch.zeros(1, self.n_mels, 216), torch.LongTensor([0]).squeeze()\n",
    "\n",
    "print(\"✅ Datasets especializados definidos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ff932a",
   "metadata": {},
   "source": [
    "## 2. Modelos de Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    \"\"\"CNN 1D para análisis directo de formas de onda\"\"\"\n",
    "    \n",
    "    def __init__(self, input_length=110250, num_classes=2):\n",
    "        super(CNN1D, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Primera capa convolucional\n",
    "            nn.Conv1d(1, 32, kernel_size=80, stride=4, padding=40),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Segunda capa\n",
    "            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            # Tercera capa\n",
    "            nn.Conv1d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            # Cuarta capa\n",
    "            nn.Conv1d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class CNN2D(nn.Module):\n",
    "    \"\"\"CNN 2D para análisis de espectrogramas\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CNN2D, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            # Primera capa\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Segunda capa\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.1),\n",
    "            \n",
    "            # Tercera capa\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "            nn.Dropout2d(0.2),\n",
    "            \n",
    "            # Cuarta capa\n",
    "            nn.Conv2d(128, 256, kernel_size=(3, 3), padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class AudioLSTM(nn.Module):\n",
    "    \"\"\"LSTM para modelado temporal de características de audio\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size=128, hidden_size=256, num_layers=2, num_classes=2):\n",
    "        super(AudioLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Extracto de características con CNN\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        \n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(128, hidden_size, num_layers, \n",
    "                           batch_first=True, dropout=0.3, bidirectional=True)\n",
    "        \n",
    "        # Clasificador\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_size * 2, 128),  # *2 por bidireccional\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extraer características\n",
    "        features = self.feature_extractor(x)  # (batch, 128, seq_len)\n",
    "        features = features.permute(0, 2, 1)  # (batch, seq_len, 128)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(features)\n",
    "        \n",
    "        # Usar la última salida\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Clasificar\n",
    "        output = self.classifier(last_output)\n",
    "        return output\n",
    "\n",
    "print(\"✅ Modelos de Deep Learning definidos\")\n",
    "print(f\"   - CNN1D: Para formas de onda directas\")\n",
    "print(f\"   - CNN2D: Para espectrogramas mel\")\n",
    "print(f\"   - AudioLSTM: Para modelado temporal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b71a05",
   "metadata": {},
   "source": [
    "## 3. Función de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=1e-3, \n",
    "                model_name=\"Model\", save_path=None):\n",
    "    \"\"\"\n",
    "    Entrenar un modelo de deep learning\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Función de pérdida y optimizador\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    \n",
    "    # Métricas de seguimiento\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"🚀 Entrenando {model_name}...\")\n",
    "    print(f\"   Épocas: {num_epochs}\")\n",
    "    print(f\"   Learning rate: {learning_rate}\")\n",
    "    print(f\"   Dispositivo: {device}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Entrenamiento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f\"Época {epoch+1}/{num_epochs} - Train\")\n",
    "        for batch_idx, (data, target) in enumerate(train_pbar):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            train_total += target.size(0)\n",
    "            train_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Actualizar barra de progreso\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{loss.item():.4f}',\n",
    "                'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Calcular métricas promedio\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_accuracy = 100. * train_correct / train_total\n",
    "        val_accuracy = 100. * val_correct / val_total\n",
    "        \n",
    "        # Guardar métricas\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Guardar mejor modelo\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        # Imprimir progreso\n",
    "        print(f\"Época {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_accuracy:.2f}%\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
    "        print(f\"  LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Early stopping simple\n",
    "        if epoch > 20 and val_accuracy < 55:  # Si no mejora después de muchas épocas\n",
    "            print(\"Early stopping - modelo no converge\")\n",
    "            break\n",
    "    \n",
    "    # Cargar mejor modelo\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Guardar modelo\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            'model_state_dict': best_model_state,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'train_accuracies': train_accuracies,\n",
    "            'val_accuracies': val_accuracies,\n",
    "            'best_val_loss': best_val_loss\n",
    "        }, save_path)\n",
    "        print(f\"💾 Modelo guardado en: {save_path}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_loss': best_val_loss\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, test_loader, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluar modelo en conjunto de test\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=f\"Evaluando {model_name}\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            # Probabilidades\n",
    "            probabilities = F.softmax(output, dim=1)\n",
    "            \n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            test_total += target.size(0)\n",
    "            test_correct += (predicted == target).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Prob clase positiva\n",
    "    \n",
    "    accuracy = 100. * test_correct / test_total\n",
    "    auc_score = roc_auc_score(all_targets, all_probabilities)\n",
    "    \n",
    "    print(f\"\\n📊 Resultados {model_name}:\")\n",
    "    print(f\"   Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"   AUC Score: {auc_score:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score,\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets,\n",
    "        'probabilities': all_probabilities\n",
    "    }\n",
    "\n",
    "print(\"✅ Funciones de entrenamiento y evaluación definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e619a9",
   "metadata": {},
   "source": [
    "## 4. Preparar Datos y Entrenar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos\n",
    "train_df, test_df = train_test_split(df_sample, test_size=0.2, random_state=42, stratify=df_sample['label'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "print(f\"📊 División de datos:\")\n",
    "print(f\"   Entrenamiento: {len(train_df)} muestras\")\n",
    "print(f\"   Validación: {len(val_df)} muestras\")\n",
    "print(f\"   Test: {len(test_df)} muestras\")\n",
    "\n",
    "# Verificar balance\n",
    "for name, df_subset in [(\"Train\", train_df), (\"Val\", val_df), (\"Test\", test_df)]:\n",
    "    balance = df_subset['label'].value_counts().sort_index()\n",
    "    print(f\"   {name} balance: {dict(balance)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración de entrenamiento\n",
    "batch_size = 16\n",
    "num_epochs = 20  # Reducido para testing rápido\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Directorio para guardar modelos\n",
    "models_dir = Path(\"../models/deep_learning\")\n",
    "models_dir.mkdir(exist_ok=True, parents=True)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "print(f\"⚙️  Configuración:\")\n",
    "print(f\"   Batch size: {batch_size}\")\n",
    "print(f\"   Épocas: {num_epochs}\")\n",
    "print(f\"   Learning rate: {learning_rate}\")\n",
    "print(f\"   Modelos se guardarán en: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8d545",
   "metadata": {},
   "source": [
    "### 4.1 Entrenar CNN 1D (Formas de onda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎵 Entrenando CNN 1D para formas de onda...\")\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset_1d = AudioWaveformDataset(train_df, duration=5.0, augment=True)\n",
    "val_dataset_1d = AudioWaveformDataset(val_df, duration=5.0, augment=False)\n",
    "test_dataset_1d = AudioWaveformDataset(test_df, duration=5.0, augment=False)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_1d = DataLoader(train_dataset_1d, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_1d = DataLoader(val_dataset_1d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_1d = DataLoader(test_dataset_1d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model_1d = CNN1D(input_length=5*22050)  # 5 segundos a 22kHz\n",
    "save_path_1d = models_dir / f\"cnn1d_{timestamp}.pth\"\n",
    "\n",
    "results_1d = train_model(\n",
    "    model_1d, train_loader_1d, val_loader_1d, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "    model_name=\"CNN1D\", save_path=save_path_1d\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "eval_results_1d = evaluate_model(results_1d['model'], test_loader_1d, \"CNN1D\")\n",
    "\n",
    "print(\"✅ CNN 1D completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d326b4",
   "metadata": {},
   "source": [
    "### 4.2 Entrenar CNN 2D (Espectrogramas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🌈 Entrenando CNN 2D para espectrogramas...\")\n",
    "\n",
    "# Crear datasets\n",
    "train_dataset_2d = SpectrogramDataset(train_df, duration=5.0, n_mels=128, augment=True)\n",
    "val_dataset_2d = SpectrogramDataset(val_df, duration=5.0, n_mels=128, augment=False)\n",
    "test_dataset_2d = SpectrogramDataset(test_df, duration=5.0, n_mels=128, augment=False)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader_2d = DataLoader(train_dataset_2d, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader_2d = DataLoader(val_dataset_2d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader_2d = DataLoader(test_dataset_2d, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model_2d = CNN2D()\n",
    "save_path_2d = models_dir / f\"cnn2d_{timestamp}.pth\"\n",
    "\n",
    "results_2d = train_model(\n",
    "    model_2d, train_loader_2d, val_loader_2d, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate,\n",
    "    model_name=\"CNN2D\", save_path=save_path_2d\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "eval_results_2d = evaluate_model(results_2d['model'], test_loader_2d, \"CNN2D\")\n",
    "\n",
    "print(\"✅ CNN 2D completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512df24a",
   "metadata": {},
   "source": [
    "### 4.3 Entrenar LSTM (Modelado temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d629bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"⏰ Entrenando LSTM para modelado temporal...\")\n",
    "\n",
    "# Usar los mismos datasets 1D para LSTM\n",
    "model_lstm = AudioLSTM()\n",
    "save_path_lstm = models_dir / f\"lstm_{timestamp}.pth\"\n",
    "\n",
    "results_lstm = train_model(\n",
    "    model_lstm, train_loader_1d, val_loader_1d, \n",
    "    num_epochs=num_epochs, learning_rate=learning_rate*0.5,  # LR más bajo para LSTM\n",
    "    model_name=\"AudioLSTM\", save_path=save_path_lstm\n",
    ")\n",
    "\n",
    "# Evaluar\n",
    "eval_results_lstm = evaluate_model(results_lstm['model'], test_loader_1d, \"AudioLSTM\")\n",
    "\n",
    "print(\"✅ LSTM completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f185cc",
   "metadata": {},
   "source": [
    "## 5. Comparación de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar resultados\n",
    "all_results = {\n",
    "    'CNN1D': eval_results_1d,\n",
    "    'CNN2D': eval_results_2d,\n",
    "    'AudioLSTM': eval_results_lstm\n",
    "}\n",
    "\n",
    "# Crear DataFrame de comparación\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': list(all_results.keys()),\n",
    "    'Accuracy': [results['accuracy'] for results in all_results.values()],\n",
    "    'AUC': [results['auc'] for results in all_results.values()]\n",
    "}).sort_values('AUC', ascending=False)\n",
    "\n",
    "print(\"🏆 COMPARACIÓN DE MODELOS DEEP LEARNING:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.round(3))\n",
    "\n",
    "# Visualización\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "axes[0].bar(comparison_df['Model'], comparison_df['Accuracy'], color='skyblue')\n",
    "axes[0].set_title('Accuracy por Modelo Deep Learning', fontweight='bold')\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# AUC comparison\n",
    "axes[1].bar(comparison_df['Model'], comparison_df['AUC'], color='lightgreen')\n",
    "axes[1].set_title('AUC Score por Modelo', fontweight='bold')\n",
    "axes[1].set_ylabel('AUC Score')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# ROC Curves\n",
    "for model_name, results in all_results.items():\n",
    "    fpr, tpr, _ = roc_curve(results['targets'], results['probabilities'])\n",
    "    axes[2].plot(fpr, tpr, label=f\"{model_name} (AUC = {results['auc']:.3f})\")\n",
    "\n",
    "axes[2].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "axes[2].set_xlabel('False Positive Rate')\n",
    "axes[2].set_ylabel('True Positive Rate')\n",
    "axes[2].set_title('ROC Curves', fontweight='bold')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mejor modelo\n",
    "best_model_name = comparison_df.iloc[0]['Model']\n",
    "best_results = all_results[best_model_name]\n",
    "\n",
    "print(f\"\\n🏆 MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_results['accuracy']:.2f}%\")\n",
    "print(f\"   AUC Score: {best_results['auc']:.3f}\")\n",
    "\n",
    "# Matriz de confusión del mejor modelo\n",
    "cm = confusion_matrix(best_results['targets'], best_results['predictions'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ambiental', 'Ultrasonido'], \n",
    "            yticklabels=['Ambiental', 'Ultrasonido'])\n",
    "plt.title(f'Matriz de Confusión - {best_model_name}', fontweight='bold')\n",
    "plt.ylabel('Verdadero')\n",
    "plt.xlabel('Predicho')\n",
    "plt.show()\n",
    "\n",
    "# Reporte detallado\n",
    "print(f\"\\n📋 Reporte de Clasificación - {best_model_name}:\")\n",
    "target_names = ['Ambiental', 'Ultrasonido']\n",
    "print(classification_report(best_results['targets'], best_results['predictions'], target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05983bb",
   "metadata": {},
   "source": [
    "## 6. Resumen y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44448a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"📋 RESUMEN FINAL - DEEP LEARNING PARA ULTRASONIDOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n🎯 OBJETIVO ALCANZADO:\")\n",
    "print(f\"   ✅ Clasificación automática: Ultrasonidos vs Sonidos Ambientales\")\n",
    "print(f\"   ✅ Múltiples arquitecturas implementadas y comparadas\")\n",
    "print(f\"   ✅ Evaluación robusta con métricas estándar\")\n",
    "\n",
    "print(f\"\\n📊 RESULTADOS OBTENIDOS:\")\n",
    "for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "    rank = \"🥇\" if i == 0 else \"🥈\" if i == 1 else \"🥉\"\n",
    "    print(f\"   {rank} {row['Model']}: {row['Accuracy']:.1f}% accuracy, {row['AUC']:.3f} AUC\")\n",
    "\n",
    "print(f\"\\n🔍 ANÁLISIS DE MODELOS:\")\n",
    "print(f\"   🎵 CNN1D: Analiza directamente las formas de onda de audio\")\n",
    "print(f\"   🌈 CNN2D: Procesa representaciones espectrales (mel-espectrogramas)\")\n",
    "print(f\"   ⏰ LSTM: Captura dependencias temporales en las señales\")\n",
    "\n",
    "print(f\"\\n🚀 PRÓXIMOS PASOS RECOMENDADOS:\")\n",
    "print(f\"   1. 📈 ESCALAR: Entrenar con dataset completo ({len(df):,} muestras)\")\n",
    "print(f\"   2. 🔧 OPTIMIZAR: Hyperparameter tuning del mejor modelo\")\n",
    "print(f\"   3. 🎭 ENSEMBLE: Combinar predicciones de múltiples modelos\")\n",
    "print(f\"   4. 📡 MULTI-CANAL: Analizar canales ch1-ch4 independientemente\")\n",
    "print(f\"   5. ⚡ TRANSFORMER: Implementar arquitectura de atención\")\n",
    "print(f\"   6. 🔄 VALIDACIÓN: Cross-validation por batches (PUA.01/PUA.02)\")\n",
    "print(f\"   7. 📱 DEPLOY: Crear API para clasificación en tiempo real\")\n",
    "\n",
    "print(f\"\\n💾 ARCHIVOS GENERADOS:\")\n",
    "print(f\"   📁 Modelos guardados en: {models_dir}\")\n",
    "saved_models = list(models_dir.glob(f\"*{timestamp}.pth\"))\n",
    "for model_path in saved_models:\n",
    "    print(f\"      - {model_path.name}\")\n",
    "\n",
    "print(f\"\\n🎯 APLICACIÓN PRÁCTICA:\")\n",
    "print(f\"   🌱 Monitoreo automático de estrés en plantas\")\n",
    "print(f\"   💧 Detección temprana de necesidades de riego\")\n",
    "print(f\"   🔬 Investigación en bioacústica vegetal\")\n",
    "print(f\"   🏭 Sistemas de agricultura inteligente\")\n",
    "\n",
    "print(f\"\\n✨ ¡Proyecto de Deep Learning completado exitosamente!\")\n",
    "print(f\"   Los modelos están listos para clasificar ultrasonidos de plantas 🌿🔊\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
