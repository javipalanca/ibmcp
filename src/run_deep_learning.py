#!/usr/bin/env python3
"""
Script de ejecuci√≥n interactivo para entrenamiento de modelos de Deep Learning
Sistema completamente automatizado con detecci√≥n de checkpoints y configuraci√≥n f√°cil
"""

import subprocess
import sys
import json
import os
import torch
from pathlib import Path
from datetime import datetime

# Configuraciones por defecto
DEFAULT_CONFIG = {
    'epochs': 25,
    'batch_size': 16,
    'learning_rate': 0.001,
    'duration': 5.0,
    'save_every': 5,
    'sample_size': None,
    'device': 'auto'
}

# Informaci√≥n de modelos
MODELS_INFO = {
    'cnn1d': {
        'name': 'CNN 1D',
        'description': 'CNN para formas de onda directas',
        'input': 'Formas de onda',
        'tiempo_aprox': '~10 min/√©poca',
        'recomendado_para': 'An√°lisis temporal directo'
    },
    'cnn2d': {
        'name': 'CNN 2D', 
        'description': 'CNN para espectrogramas mel',
        'input': 'Espectrogramas',
        'tiempo_aprox': '~15 min/√©poca',
        'recomendado_para': 'An√°lisis frecuencial'
    },
    'resnet': {
        'name': 'ResNet Audio',
        'description': 'ResNet adaptada para audio',
        'input': 'Espectrogramas',
        'tiempo_aprox': '~20 min/√©poca',
        'recomendado_para': 'M√°xima precisi√≥n'
    },
    'lstm': {
        'name': 'LSTM',
        'description': 'LSTM para modelado temporal',
        'input': 'Secuencias temporales',
        'tiempo_aprox': '~25 min/√©poca',
        'recomendado_para': 'Patrones temporales largos'
    },
    'gru': {
        'name': 'GRU',
        'description': 'GRU alternativo m√°s r√°pido',
        'input': 'Secuencias temporales',
        'tiempo_aprox': '~20 min/√©poca',
        'recomendado_para': 'Eficiencia temporal'
    },
    'hybrid': {
        'name': 'CNN-LSTM H√≠brido',
        'description': 'Combina CNN y LSTM',
        'input': 'Formas de onda',
        'tiempo_aprox': '~30 min/√©poca',
        'recomendado_para': 'M√°ximo rendimiento'
    }
}

def load_config():
    """Cargar configuraci√≥n guardada si existe"""
    config_file = Path('dl_config.json')
    if config_file.exists():
        try:
            with open(config_file, 'r') as f:
                saved_config = json.load(f)
            # Combinar con defaults
            config = DEFAULT_CONFIG.copy()
            config.update(saved_config)
            return config
        except:
            pass
    return DEFAULT_CONFIG.copy()

def save_config(config):
    """Guardar configuraci√≥n actual"""
    config_file = Path('dl_config.json')
    try:
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
    except:
        pass

def detect_checkpoints():
    """Detectar checkpoints existentes"""
    checkpoint_dir = Path('../checkpoints')
    if not checkpoint_dir.exists():
        return {}
    
    checkpoints = {}
    for model_dir in checkpoint_dir.iterdir():
        if model_dir.is_dir():
            model_name = model_dir.name
            checkpoint_files = list(model_dir.glob('*_checkpoint_epoch_*.pt'))
            if checkpoint_files:
                # Ordenar por √©poca (m√°s reciente primero)
                checkpoint_files.sort(key=lambda x: int(x.name.split('_epoch_')[1].split('.')[0]), reverse=True)
                latest = checkpoint_files[0]
                epoch = int(latest.name.split('_epoch_')[1].split('.')[0])
                checkpoints[model_name] = {
                    'path': latest,
                    'epoch': epoch,
                    'file': latest.name,
                    'date': datetime.fromtimestamp(latest.stat().st_mtime).strftime('%Y-%m-%d %H:%M')
                }
    
    return checkpoints

def detect_existing_results():
    """Detectar modelos ya entrenados"""
    results_dir = Path('../models')
    if not results_dir.exists():
        return {}
    
    results = {}
    for results_file in results_dir.glob('*_results_*.json'):
        try:
            model_name = results_file.name.split('_results_')[0]
            timestamp = results_file.name.split('_results_')[1].replace('.json', '')
            date = datetime.strptime(timestamp, '%Y%m%d_%H%M%S').strftime('%Y-%m-%d %H:%M')
            
            with open(results_file, 'r') as f:
                data = json.load(f)
            
            results[model_name] = {
                'accuracy': data.get('accuracy', 0),
                'auc': data.get('auc', 0),
                'date': date,
                'file': results_file.name
            }
        except:
            continue
    
    return results

def print_model_info():
    """Mostrar informaci√≥n detallada de modelos"""
    print("\nüìã MODELOS DISPONIBLES:")
    print("="*80)
    
    for i, (model_id, info) in enumerate(MODELS_INFO.items(), 1):
        print(f"{i}. {info['name']} ({model_id})")
        print(f"   üìù {info['description']}")
        print(f"   üìä Entrada: {info['input']}")
        print(f"   ‚è±Ô∏è  Tiempo: {info['tiempo_aprox']}")
        print(f"   üéØ Recomendado para: {info['recomendado_para']}")
        print()

def select_models():
    """Seleccionar modelos interactivamente"""
    print_model_info()
    
    print("Opciones de selecci√≥n:")
    print("0. Todos los modelos")
    print("7. Configuraci√≥n personalizada")
    print("8. Solo evaluaci√≥n de modelos existentes")
    
    while True:
        try:
            choice = input("\n>>> Selecciona opci√≥n (0-8): ").strip()
            
            if choice == "0":
                return list(MODELS_INFO.keys())
            elif choice == "8":
                return ["eval-only"]
            elif choice == "7":
                return select_custom_models()
            elif choice in ["1", "2", "3", "4", "5", "6"]:
                model_id = list(MODELS_INFO.keys())[int(choice) - 1]
                return [model_id]
            else:
                print("‚ùå Opci√≥n no v√°lida. Intenta de nuevo.")
        except (ValueError, IndexError):
            print("‚ùå Entrada inv√°lida. Usa n√∫meros del 0-8.")

def select_custom_models():
    """Selecci√≥n personalizada de m√∫ltiples modelos"""
    print("\nSelecci√≥n personalizada - Ingresa los n√∫meros separados por comas (ej: 1,3,5)")
    print("O usa 'all' para todos los modelos")
    
    while True:
        selection = input(">>> Modelos: ").strip().lower()
        
        if selection == "all":
            return list(MODELS_INFO.keys())
        
        try:
            indices = [int(x.strip()) for x in selection.split(',')]
            models = []
            for idx in indices:
                if 1 <= idx <= len(MODELS_INFO):
                    model_id = list(MODELS_INFO.keys())[idx - 1]
                    models.append(model_id)
                else:
                    raise ValueError()
            
            if models:
                return models
            else:
                print("‚ùå No se seleccionaron modelos v√°lidos.")
        except ValueError:
            print("‚ùå Formato inv√°lido. Usa n√∫meros separados por comas (ej: 1,3,5)")

def validate_config(config):
    """Validar configuraci√≥n y mostrar advertencias"""
    warnings = []
    
    # Validar duraci√≥n m√≠nima
    if config['duration'] < 2.0:
        warnings.append(f"‚ö†Ô∏è  Duraci√≥n muy corta ({config['duration']}s). Recomendado: 3-10s")
    
    # Validar batch size vs GPU
    if config['device'] == 'cuda' and config['batch_size'] > 128:
        warnings.append(f"‚ö†Ô∏è  Batch size muy grande ({config['batch_size']}). Podr√≠a causar error de memoria")
    
    # Validar learning rate
    if config['learning_rate'] > 0.01:
        warnings.append(f"‚ö†Ô∏è  Learning rate alto ({config['learning_rate']}). Podr√≠a causar inestabilidad")
    elif config['learning_rate'] < 1e-5:
        warnings.append(f"‚ö†Ô∏è  Learning rate muy bajo ({config['learning_rate']}). Entrenamiento muy lento")
    
    # Validar √©pocas vs muestra
    if config['sample_size'] and config['sample_size'] < 1000 and config['epochs'] > 20:
        warnings.append(f"‚ö†Ô∏è  Muchas √©pocas ({config['epochs']}) para muestra peque√±a ({config['sample_size']})")
    
    return warnings

def configure_hyperparameters(current_config):
    """Configurar hiperpar√°metros interactivamente"""
    print("\n‚öôÔ∏è  CONFIGURACI√ìN DE HIPERPAR√ÅMETROS")
    print("="*50)
    print("Presiona Enter para mantener el valor actual")
    
    config = current_config.copy()
    
    # √âpocas
    print(f"\nüî¢ √âpocas (actual: {config['epochs']})")
    print("   Recomendado: 5-10 para pruebas, 25-50 para producci√≥n")
    new_epochs = input(">>> √âpocas: ").strip()
    if new_epochs:
        try:
            config['epochs'] = int(new_epochs)
        except ValueError:
            print("‚ö†Ô∏è  Valor inv√°lido, manteniendo actual")
    
    # Batch size
    print(f"\nüì¶ Batch Size (actual: {config['batch_size']})")
    print("   Recomendado: 8-16 para GPU con poca memoria, 32-64 para GPU potente")
    new_batch = input(">>> Batch size: ").strip()
    if new_batch:
        try:
            config['batch_size'] = int(new_batch)
        except ValueError:
            print("‚ö†Ô∏è  Valor inv√°lido, manteniendo actual")
    
    # Learning rate
    print(f"\nüìà Learning Rate (actual: {config['learning_rate']})")
    print("   Recomendado: 0.001 est√°ndar, 0.0001 para ajuste fino, 0.01 para convergencia r√°pida")
    new_lr = input(">>> Learning rate: ").strip()
    if new_lr:
        try:
            config['learning_rate'] = float(new_lr)
        except ValueError:
            print("‚ö†Ô∏è  Valor inv√°lido, manteniendo actual")
    
    # Duraci√≥n de audio
    print(f"\nüéµ Duraci√≥n de audio en segundos (actual: {config['duration']})")
    print("   Recomendado: 3-10 segundos para balance tiempo/informaci√≥n")
    print("   M√çNIMO: 2 segundos (duraciones menores causan errores)")
    new_duration = input(">>> Duraci√≥n: ").strip()
    if new_duration:
        try:
            duration = float(new_duration)
            if duration < 1.0:
                print("‚ö†Ô∏è  Duraci√≥n demasiado corta, estableciendo m√≠nimo de 2s")
                config['duration'] = 2.0
            else:
                config['duration'] = duration
        except ValueError:
            print("‚ö†Ô∏è  Valor inv√°lido, manteniendo actual")
    
    # Tama√±o de muestra
    current_sample = config['sample_size'] or "Completo"
    print(f"\nüéØ Tama√±o de muestra (actual: {current_sample})")
    print("   Ejemplos: 100 para pruebas r√°pidas, 1000 para validaci√≥n, vac√≠o para dataset completo")
    new_sample = input(">>> Tama√±o muestra: ").strip()
    if new_sample:
        try:
            if new_sample.lower() in ["completo", "full", ""]:
                config['sample_size'] = None
            else:
                sample_size = int(new_sample)
                if sample_size < 50:
                    print("‚ö†Ô∏è  Muestra muy peque√±a, estableciendo m√≠nimo de 50")
                    config['sample_size'] = 50
                else:
                    config['sample_size'] = sample_size
        except ValueError:
            print("‚ö†Ô∏è  Valor inv√°lido, manteniendo actual")
    
    # Frecuencia de guardado
    print(f"\nüíæ Guardar checkpoint cada N √©pocas (actual: {config['save_every']})")
    print("   Recomendado: 5 para entrenamientos largos, 2-3 para monitoreo frecuente")
    new_save = input(">>> Frecuencia guardado: ").strip()
    if new_save:
        try:
            config['save_every'] = max(1, int(new_save))
        except ValueError:
            print("‚ö†Ô∏è  Valor inv√°lido, manteniendo actual")
    
    # Dispositivo
    print(f"\nüñ•Ô∏è  Dispositivo (actual: {config['device']})")
    print("   Opciones: auto (detectar autom√°ticamente), cpu, cuda")
    new_device = input(">>> Dispositivo: ").strip().lower()
    if new_device and new_device in ['auto', 'cpu', 'cuda']:
        config['device'] = new_device
    elif new_device:
        print("‚ö†Ô∏è  Dispositivo inv√°lido, manteniendo actual")
    
    # Validar configuraci√≥n
    warnings = validate_config(config)
    if warnings:
        print(f"\n‚ö†Ô∏è  ADVERTENCIAS DE CONFIGURACI√ìN:")
        for warning in warnings:
            print(f"   {warning}")
        
        fix_config = input("\n¬øAplicar correcciones autom√°ticas? (Y/n): ").strip().lower()
        if fix_config != 'n':
            config = apply_auto_corrections(config)
    
    return config

def apply_auto_corrections(config):
    """Aplicar correcciones autom√°ticas a la configuraci√≥n"""
    print("\nüîß Aplicando correcciones autom√°ticas...")
    
    # Corregir duraci√≥n m√≠nima
    if config['duration'] < 2.0:
        config['duration'] = 3.0
        print(f"   ‚úÖ Duraci√≥n corregida a {config['duration']}s")
    
    # Corregir batch size para GPU
    if config['device'] == 'cuda' and config['batch_size'] > 128:
        config['batch_size'] = 32
        print(f"   ‚úÖ Batch size corregido a {config['batch_size']}")
    
    # Corregir learning rate
    if config['learning_rate'] > 0.01:
        config['learning_rate'] = 0.001
        print(f"   ‚úÖ Learning rate corregido a {config['learning_rate']}")
    elif config['learning_rate'] < 1e-5:
        config['learning_rate'] = 1e-4
        print(f"   ‚úÖ Learning rate corregido a {config['learning_rate']}")
    
    # Corregir √©pocas vs muestra
    if config['sample_size'] and config['sample_size'] < 1000 and config['epochs'] > 20:
        config['epochs'] = 10
        print(f"   ‚úÖ √âpocas corregidas a {config['epochs']} para muestra peque√±a")
    
    return config

def handle_checkpoints(models, checkpoints):
    """Manejar checkpoints existentes"""
    if not checkpoints:
        return False, []
    
    # Filtrar checkpoints de modelos seleccionados
    relevant_checkpoints = {k: v for k, v in checkpoints.items() if k in models}
    
    if not relevant_checkpoints:
        return False, []
    
    print("\nüîÑ CHECKPOINTS DETECTADOS")
    print("="*40)
    for model, info in relevant_checkpoints.items():
        print(f"üìÅ {model}: √âpoca {info['epoch']} ({info['date']})")
    
    print("\nOpciones:")
    print("1. Continuar desde checkpoints")
    print("2. Empezar desde cero")
    print("3. Ver detalles de checkpoints")
    
    while True:
        choice = input(">>> Opci√≥n (1-3): ").strip()
        
        if choice == "1":
            return True, relevant_checkpoints
        elif choice == "2":
            # Preguntar si eliminar checkpoints
            delete = input("¬øEliminar checkpoints existentes? (y/N): ").strip().lower()
            if delete == 'y':
                for info in relevant_checkpoints.values():
                    try:
                        info['path'].unlink()
                        print(f"üóëÔ∏è  Eliminado: {info['file']}")
                    except:
                        pass
            return False, []
        elif choice == "3":
            show_checkpoint_details(relevant_checkpoints)
        else:
            print("‚ùå Opci√≥n no v√°lida.")

def show_checkpoint_details(checkpoints):
    """Mostrar detalles de checkpoints"""
    print("\nüìä DETALLES DE CHECKPOINTS")
    print("="*50)
    
    for model, info in checkpoints.items():
        print(f"\nüéØ {model.upper()}")
        print(f"   üìÑ Archivo: {info['file']}")
        print(f"   üìÖ Fecha: {info['date']}")
        print(f"   üî¢ √âpoca: {info['epoch']}")
        print(f"   üìç Ruta: {info['path']}")
        
        # Intentar leer m√©tricas del checkpoint si es posible
        try:
            import torch
            checkpoint_data = torch.load(info['path'], map_location='cpu')
            if 'metrics' in checkpoint_data:
                metrics = checkpoint_data['metrics']
                if 'best_val_acc' in metrics:
                    print(f"   üéØ Mejor accuracy: {metrics['best_val_acc']:.2f}%")
        except:
            pass

def show_existing_results(results):
    """Mostrar resultados de modelos ya entrenados"""
    if not results:
        print("\nüìä No hay modelos entrenados previamente")
        return
    
    print("\nüèÜ MODELOS YA ENTRENADOS")
    print("="*50)
    
    # Ordenar por AUC
    sorted_results = sorted(results.items(), key=lambda x: x[1]['auc'], reverse=True)
    
    for model, info in sorted_results:
        print(f"\nüéØ {model.upper()}")
        print(f"   üéØ Accuracy: {info['accuracy']:.2f}%")
        print(f"   üìà AUC: {info['auc']:.3f}")
        print(f"   üìÖ Fecha: {info['date']}")

def estimate_time(models, config):
    """Estimar tiempo total de entrenamiento"""
    time_per_epoch = {
        'cnn1d': 10,
        'cnn2d': 15, 
        'resnet': 20,
        'lstm': 25,
        'gru': 20,
        'hybrid': 30
    }
    
    total_minutes = 0
    epochs = config['epochs']
    
    for model in models:
        if model in time_per_epoch:
            total_minutes += time_per_epoch[model] * epochs
    
    # Ajustar por tama√±o de muestra
    if config['sample_size']:
        # Escalado aproximado
        factor = min(1.0, config['sample_size'] / 10000)
        total_minutes *= factor
    
    hours = total_minutes // 60
    minutes = total_minutes % 60
    
    return hours, minutes

def print_summary(models, config, use_checkpoints, time_estimate):
    """Mostrar resumen de la configuraci√≥n"""
    print("\nüìã RESUMEN DE CONFIGURACI√ìN")
    print("="*50)
    
    # Modelos
    if models == ["eval-only"]:
        print("üéØ Modo: Solo evaluaci√≥n")
    else:
        print(f"üéØ Modelos: {', '.join(models)}")
    
    # Configuraci√≥n
    print(f"üî¢ √âpocas: {config['epochs']}")
    print(f"üì¶ Batch size: {config['batch_size']}")
    print(f"üìà Learning rate: {config['learning_rate']}")
    print(f"üéµ Duraci√≥n audio: {config['duration']}s")
    
    sample_text = f"{config['sample_size']:,}" if config['sample_size'] else "Completo"
    print(f"üéØ Tama√±o muestra: {sample_text}")
    
    print(f"üíæ Checkpoint cada: {config['save_every']} √©pocas")
    print(f"üñ•Ô∏è  Dispositivo: {config['device']}")
    
    # Checkpoints
    if use_checkpoints:
        print("üîÑ Continuar desde checkpoints: S√≠")
    
    # Tiempo estimado
    if models != ["eval-only"] and time_estimate[0] > 0 or time_estimate[1] > 0:
        if time_estimate[0] > 0:
            print(f"‚è±Ô∏è  Tiempo estimado: {time_estimate[0]}h {time_estimate[1]}min")
        else:
            print(f"‚è±Ô∏è  Tiempo estimado: {time_estimate[1]}min")

def build_command(models, config, use_checkpoints, checkpoints):
    """Construir comando de ejecuci√≥n"""
    cmd = [sys.executable, "deep_learning_training.py"]
    
    # Modelos
    if models == ["eval-only"]:
        cmd.append("--eval-only")
    else:
        cmd.extend(["--models"] + models)
    
    # Configuraci√≥n
    cmd.extend([
        "--epochs", str(config['epochs']),
        "--batch-size", str(config['batch_size']),
        "--learning-rate", str(config['learning_rate']),
        "--duration", str(config['duration']),
        "--save-every", str(config['save_every']),
        "--device", config['device']
    ])
    
    if config['sample_size']:
        cmd.extend(["--sample-size", str(config['sample_size'])])
    
    # A√±adir opci√≥n para continuar desde checkpoints
    if use_checkpoints:
        cmd.append("--resume-from-checkpoints")
    
    # A√±adir estrategia de GPU si es relevante
    if torch.cuda.is_available():
        cmd.extend(["--gpu-strategy", "optimal"])
    
    return cmd

def main():
    """Funci√≥n principal completamente interactiva"""
    
    print("üéµ SISTEMA INTERACTIVO DE DEEP LEARNING")
    print("="*60)
    print("ü§ñ Configuraci√≥n autom√°tica y detecci√≥n inteligente")
    
    # Mostrar informaci√≥n de GPU
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"üöÄ GPUs detectadas: {gpu_count}")
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)")
    else:
        print("üîß No hay GPU disponible - usando CPU")
    
    # Cargar configuraci√≥n previa
    config = load_config()
    
    # Detectar estado actual
    print("\nüîç Detectando estado del sistema...")
    checkpoints = detect_checkpoints()
    existing_results = detect_existing_results()
    
    if checkpoints:
        print(f"‚úÖ Detectados {len(checkpoints)} checkpoints")
    if existing_results:
        print(f"‚úÖ Detectados {len(existing_results)} modelos entrenados")
    
    # Mostrar resultados existentes si los hay
    if existing_results:
        show_existing_results(existing_results)
    
    print("\n" + "="*60)
    
    # Men√∫ principal
    while True:
        print("\nüéØ ¬øQU√â QUIERES HACER?")
        print("1. üöÄ Entrenar modelo(s)")
        print("2. ‚öôÔ∏è  Configurar hiperpar√°metros")
        print("3. üìä Solo evaluar modelos existentes")
        print("4. üóëÔ∏è  Limpiar checkpoints/resultados")
        print("5. ‚ùì Ayuda y ejemplos")
        print("0. üö™ Salir")
        
        choice = input("\n>>> Opci√≥n: ").strip()
        
        if choice == "0":
            print("üëã ¬°Hasta luego!")
            break
            
        elif choice == "1":
            # Entrenar modelos
            train_workflow(config, checkpoints, existing_results)
            break
            
        elif choice == "2":
            # Configurar hiperpar√°metros
            config = configure_hyperparameters(config)
            save_config(config)
            print("\n‚úÖ Configuraci√≥n guardada")
            
        elif choice == "3":
            # Solo evaluaci√≥n
            if existing_results:
                confirm = input("\n¬øEjecutar evaluaci√≥n de modelos existentes? (Y/n): ").strip().lower()
                if confirm != 'n':
                    run_evaluation()
                    break
            else:
                print("\n‚ùå No hay modelos entrenados para evaluar")
                
        elif choice == "4":
            # Limpiar datos
            cleanup_menu(checkpoints, existing_results)
            # Redetectar despu√©s de limpieza
            checkpoints = detect_checkpoints()
            existing_results = detect_existing_results()
            
        elif choice == "5":
            # Ayuda
            show_help()
            
        else:
            print("‚ùå Opci√≥n no v√°lida")

def train_workflow(config, checkpoints, existing_results):
    """Flujo completo de entrenamiento"""
    
    # 1. Seleccionar modelos
    print("\n" + "="*60)
    print("PASO 1: SELECCI√ìN DE MODELOS")
    models = select_models()
    
    if models == ["eval-only"]:
        run_evaluation()
        return
    
    # 2. Configurar hiperpar√°metros
    print("\n" + "="*60)
    print("PASO 2: CONFIGURACI√ìN")
    
    print(f"\nConfiguraci√≥n actual:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    change_config = input("\n¬øCambiar configuraci√≥n? (y/N): ").strip().lower()
    if change_config == 'y':
        config = configure_hyperparameters(config)
        save_config(config)
    
    # 3. Manejar checkpoints
    print("\n" + "="*60)
    print("PASO 3: CHECKPOINTS")
    
    use_checkpoints = False
    relevant_checkpoints = {}
    
    if checkpoints:
        use_checkpoints, relevant_checkpoints = handle_checkpoints(models, checkpoints)
    else:
        print("‚ÑπÔ∏è  No hay checkpoints existentes. Empezando desde cero.")
    
    # 4. Estimar tiempo
    time_estimate = estimate_time(models, config)
    
    # 5. Mostrar resumen y confirmar
    print("\n" + "="*60)
    print("PASO 4: CONFIRMACI√ìN")
    
    print_summary(models, config, use_checkpoints, time_estimate)
    
    # 6. Confirmar ejecuci√≥n
    print("\nüéØ ¬øPROCEDER CON EL ENTRENAMIENTO?")
    
    if time_estimate[0] > 2:  # M√°s de 2 horas
        print("‚ö†Ô∏è  ATENCI√ìN: El entrenamiento tomar√° mucho tiempo")
        print("   Recomendaci√≥n: Ejecutar en screen/tmux o usar muestra m√°s peque√±a")
    
    confirm = input("\n¬øContinuar? (Y/n): ").strip().lower()
    if confirm == 'n':
        print("‚ùå Entrenamiento cancelado")
        return
    
    # 7. Ejecutar
    print("\n" + "="*60)
    print("üöÄ INICIANDO ENTRENAMIENTO")
    
    cmd = build_command(models, config, use_checkpoints, relevant_checkpoints)
    print(f"üìã Comando: {' '.join(cmd)}")
    
    # Mostrar tip para interrumpir
    print("\nüí° TIPS:")
    print("   - Ctrl+C para interrumpir (guarda checkpoint autom√°tico)")
    print("   - Los checkpoints se guardan autom√°ticamente")
    print("   - Resultados se guardan en ../models/")
    
    input("\nPresiona Enter para comenzar...")
    
    try:
        subprocess.run(cmd)
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Entrenamiento interrumpido por el usuario")

def cleanup_menu(checkpoints, existing_results):
    """Men√∫ de limpieza"""
    print("\nüóëÔ∏è  LIMPIEZA DE DATOS")
    print("="*30)
    
    print("¬øQu√© quieres limpiar?")
    print("1. Checkpoints")
    print("2. Resultados de modelos")
    print("3. Todo")
    print("0. Cancelar")
    
    choice = input("\n>>> Opci√≥n: ").strip()
    
    if choice == "1" and checkpoints:
        cleanup_checkpoints(checkpoints)
    elif choice == "2" and existing_results:
        cleanup_results(existing_results)
    elif choice == "3":
        if checkpoints:
            cleanup_checkpoints(checkpoints)
        if existing_results:
            cleanup_results(existing_results)
        cleanup_config()
    elif choice == "0":
        return
    else:
        print("‚ùå Opci√≥n no v√°lida o no hay datos para limpiar")

def cleanup_checkpoints(checkpoints):
    """Limpiar checkpoints"""
    print(f"\nüóëÔ∏è  Limpiando {len(checkpoints)} checkpoints...")
    
    for model, info in checkpoints.items():
        try:
            # Eliminar archivo de checkpoint
            info['path'].unlink()
            print(f"‚úÖ Eliminado checkpoint de {model}")
            
            # Eliminar directorio si est√° vac√≠o
            if not any(info['path'].parent.iterdir()):
                info['path'].parent.rmdir()
                
        except Exception as e:
            print(f"‚ùå Error eliminando {model}: {e}")

def cleanup_results(existing_results):
    """Limpiar resultados"""
    print(f"\nüóëÔ∏è  Limpiando {len(existing_results)} resultados...")
    
    results_dir = Path('../models')
    for model, info in existing_results.items():
        try:
            # Buscar y eliminar archivos relacionados
            pattern = f"{model}_*"
            for file_path in results_dir.glob(pattern):
                file_path.unlink()
                print(f"‚úÖ Eliminado {file_path.name}")
                
        except Exception as e:
            print(f"‚ùå Error eliminando archivos de {model}: {e}")

def cleanup_config():
    """Limpiar configuraci√≥n"""
    config_file = Path('dl_config.json')
    if config_file.exists():
        config_file.unlink()
        print("‚úÖ Configuraci√≥n eliminada")

def run_evaluation():
    """Ejecutar solo evaluaci√≥n"""
    cmd = [sys.executable, "deep_learning_training.py", "--eval-only"]
    print("üìä Ejecutando evaluaci√≥n de modelos existentes...")
    print(f"Comando: {' '.join(cmd)}")
    subprocess.run(cmd)

def show_help():
    """Mostrar ayuda detallada"""
    print("\n‚ùì AYUDA DEL SISTEMA")
    print("="*50)
    
    print("\nüéØ FLUJO T√çPICO:")
    print("1. Configurar hiperpar√°metros (una vez)")
    print("2. Seleccionar modelo(s) a entrenar") 
    print("3. El sistema detecta checkpoints autom√°ticamente")
    print("4. Elegir continuar o empezar desde cero")
    print("5. Revisar resumen y confirmar")
    print("6. ¬°Entrenar!")
    
    print("\nüí° RECOMENDACIONES:")
    print("üî∏ Para pruebas: 1 modelo, muestra 100-500, 5 √©pocas")
    print("üî∏ Para validaci√≥n: 2-3 modelos, muestra 1000, 15 √©pocas")
    print("üî∏ Para producci√≥n: Todos modelos, dataset completo, 25-50 √©pocas")
    
    print("\n‚ö° OPTIMIZACI√ìN:")
    print("üî∏ GPU recomendada para entrenamiento")
    print("üî∏ Usar batch_size m√°s grande si tienes memoria GPU")
    print("üî∏ Los checkpoints permiten reanudar entrenamiento")
    
    print("\nüìÅ ARCHIVOS GENERADOS:")
    print("üî∏ ../checkpoints/: Checkpoints por modelo")
    print("üî∏ ../models/: Modelos finales y resultados")
    print("üî∏ dl_config.json: Tu configuraci√≥n guardada")
    
    print("\nüÜò SOLUCI√ìN DE PROBLEMAS:")
    print("üî∏ Error de memoria: Reducir batch_size")
    print("üî∏ Entrenamiento lento: Usar GPU o muestra m√°s peque√±a")
    print("üî∏ Interrumpir: Ctrl+C (guarda checkpoint autom√°tico)")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nüëã ¬°Hasta luego!")
    except Exception as e:
        print(f"\n‚ùå Error inesperado: {e}")
        print("üí° Intenta de nuevo o reporta el problema")
