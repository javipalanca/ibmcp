#!/usr/bin/env python3
"""
Script de ejecuciÃ³n interactivo para entrenamiento de modelos de Deep Learning
Sistema completamente automatizado con detecciÃ³n de checkpoints y configuraciÃ³n fÃ¡cil
"""

import subprocess
import sys
import json
import os
import torch
from pathlib import Path
from datetime import datetime

# Configuraciones por defecto
DEFAULT_CONFIG = {
    'epochs': 25,
    'batch_size': 16,
    'learning_rate': 0.001,
    'duration': 5.0,
    'save_every': 5,
    'sample_size': None,
    'device': 'auto'
}

# InformaciÃ³n de modelos
MODELS_INFO = {
    'cnn1d': {
        'name': 'CNN 1D',
        'description': 'CNN para formas de onda directas',
        'input': 'Formas de onda',
        'tiempo_aprox': '~10 min/Ã©poca',
        'recomendado_para': 'AnÃ¡lisis temporal directo'
    },
    'cnn2d': {
        'name': 'CNN 2D', 
        'description': 'CNN para espectrogramas mel',
        'input': 'Espectrogramas',
        'tiempo_aprox': '~15 min/Ã©poca',
        'recomendado_para': 'AnÃ¡lisis frecuencial'
    },
    'resnet': {
        'name': 'ResNet Audio',
        'description': 'ResNet adaptada para audio',
        'input': 'Espectrogramas',
        'tiempo_aprox': '~20 min/Ã©poca',
        'recomendado_para': 'MÃ¡xima precisiÃ³n'
    },
    'lstm': {
        'name': 'LSTM',
        'description': 'LSTM para modelado temporal',
        'input': 'Secuencias temporales',
        'tiempo_aprox': '~25 min/Ã©poca',
        'recomendado_para': 'Patrones temporales largos'
    },
    'gru': {
        'name': 'GRU',
        'description': 'GRU alternativo mÃ¡s rÃ¡pido',
        'input': 'Secuencias temporales',
        'tiempo_aprox': '~20 min/Ã©poca',
        'recomendado_para': 'Eficiencia temporal'
    },
    'hybrid': {
        'name': 'CNN-LSTM HÃ­brido',
        'description': 'Combina CNN y LSTM',
        'input': 'Formas de onda',
        'tiempo_aprox': '~30 min/Ã©poca',
        'recomendado_para': 'MÃ¡ximo rendimiento'
    }
}

def load_config():
    """Cargar configuraciÃ³n guardada si existe"""
    config_file = Path('dl_config.json')
    if config_file.exists():
        try:
            with open(config_file, 'r') as f:
                saved_config = json.load(f)
            # Combinar con defaults
            config = DEFAULT_CONFIG.copy()
            config.update(saved_config)
            return config
        except:
            pass
    return DEFAULT_CONFIG.copy()

def save_config(config):
    """Guardar configuraciÃ³n actual"""
    config_file = Path('dl_config.json')
    try:
        with open(config_file, 'w') as f:
            json.dump(config, f, indent=2)
    except:
        pass

def detect_checkpoints():
    """Detectar checkpoints existentes"""
    checkpoint_dir = Path('../checkpoints')
    if not checkpoint_dir.exists():
        return {}
    
    checkpoints = {}
    for model_dir in checkpoint_dir.iterdir():
        if model_dir.is_dir():
            model_name = model_dir.name
            checkpoint_files = list(model_dir.glob('*_checkpoint_epoch_*.pt'))
            if checkpoint_files:
                # Ordenar por Ã©poca (mÃ¡s reciente primero)
                checkpoint_files.sort(key=lambda x: int(x.name.split('_epoch_')[1].split('.')[0]), reverse=True)
                latest = checkpoint_files[0]
                epoch = int(latest.name.split('_epoch_')[1].split('.')[0])
                checkpoints[model_name] = {
                    'path': latest,
                    'epoch': epoch,
                    'file': latest.name,
                    'date': datetime.fromtimestamp(latest.stat().st_mtime).strftime('%Y-%m-%d %H:%M')
                }
    
    return checkpoints

def detect_existing_results():
    """Detectar modelos ya entrenados"""
    results_dir = Path('../models')
    if not results_dir.exists():
        return {}
    
    results = {}
    for results_file in results_dir.glob('*_results_*.json'):
        try:
            model_name = results_file.name.split('_results_')[0]
            timestamp = results_file.name.split('_results_')[1].replace('.json', '')
            date = datetime.strptime(timestamp, '%Y%m%d_%H%M%S').strftime('%Y-%m-%d %H:%M')
            
            with open(results_file, 'r') as f:
                data = json.load(f)
            
            results[model_name] = {
                'accuracy': data.get('accuracy', 0),
                'auc': data.get('auc', 0),
                'date': date,
                'file': results_file.name
            }
        except:
            continue
    
    return results

def print_model_info():
    """Mostrar informaciÃ³n detallada de modelos"""
    print("\nğŸ“‹ MODELOS DISPONIBLES:")
    print("="*80)
    
    for i, (model_id, info) in enumerate(MODELS_INFO.items(), 1):
        print(f"{i}. {info['name']} ({model_id})")
        print(f"   ğŸ“ {info['description']}")
        print(f"   ğŸ“Š Entrada: {info['input']}")
        print(f"   â±ï¸  Tiempo: {info['tiempo_aprox']}")
        print(f"   ğŸ¯ Recomendado para: {info['recomendado_para']}")
        print()

def select_models():
    """Seleccionar modelos interactivamente"""
    print_model_info()
    
    print("Opciones de selecciÃ³n:")
    print("0. Todos los modelos")
    print("7. ConfiguraciÃ³n personalizada")
    print("8. Solo evaluaciÃ³n de modelos existentes")
    
    while True:
        try:
            choice = input("\n>>> Selecciona opciÃ³n (0-8): ").strip()
            
            if choice == "0":
                return list(MODELS_INFO.keys())
            elif choice == "8":
                return ["eval-only"]
            elif choice == "7":
                return select_custom_models()
            elif choice in ["1", "2", "3", "4", "5", "6"]:
                model_id = list(MODELS_INFO.keys())[int(choice) - 1]
                return [model_id]
            else:
                print("âŒ OpciÃ³n no vÃ¡lida. Intenta de nuevo.")
        except (ValueError, IndexError):
            print("âŒ Entrada invÃ¡lida. Usa nÃºmeros del 0-8.")

def select_custom_models():
    """SelecciÃ³n personalizada de mÃºltiples modelos"""
    print("\nSelecciÃ³n personalizada - Ingresa los nÃºmeros separados por comas (ej: 1,3,5)")
    print("O usa 'all' para todos los modelos")
    
    while True:
        selection = input(">>> Modelos: ").strip().lower()
        
        if selection == "all":
            return list(MODELS_INFO.keys())
        
        try:
            indices = [int(x.strip()) for x in selection.split(',')]
            models = []
            for idx in indices:
                if 1 <= idx <= len(MODELS_INFO):
                    model_id = list(MODELS_INFO.keys())[idx - 1]
                    models.append(model_id)
                else:
                    raise ValueError()
            
            if models:
                return models
            else:
                print("âŒ No se seleccionaron modelos vÃ¡lidos.")
        except ValueError:
            print("âŒ Formato invÃ¡lido. Usa nÃºmeros separados por comas (ej: 1,3,5)")

def validate_config(config):
    """Validar configuraciÃ³n y mostrar advertencias"""
    warnings = []
    
    # Validar duraciÃ³n mÃ­nima
    if config['duration'] < 2.0:
        warnings.append(f"âš ï¸  DuraciÃ³n muy corta ({config['duration']}s). Recomendado: 3-10s")
    
    # Validar batch size vs GPU
    if config['device'] == 'cuda' and config['batch_size'] > 128:
        warnings.append(f"âš ï¸  Batch size muy grande ({config['batch_size']}). PodrÃ­a causar error de memoria")
    
    # Validar learning rate
    if config['learning_rate'] > 0.01:
        warnings.append(f"âš ï¸  Learning rate alto ({config['learning_rate']}). PodrÃ­a causar inestabilidad")
    elif config['learning_rate'] < 1e-5:
        warnings.append(f"âš ï¸  Learning rate muy bajo ({config['learning_rate']}). Entrenamiento muy lento")
    
    # Validar Ã©pocas vs muestra
    if config['sample_size'] and config['sample_size'] < 1000 and config['epochs'] > 20:
        warnings.append(f"âš ï¸  Muchas Ã©pocas ({config['epochs']}) para muestra pequeÃ±a ({config['sample_size']})")
    
    return warnings

def configure_hyperparameters(current_config):
    """Configurar hiperparÃ¡metros interactivamente"""
    print("\nâš™ï¸  CONFIGURACIÃ“N DE HIPERPARÃMETROS")
    print("="*50)
    print("Presiona Enter para mantener el valor actual")
    
    config = current_config.copy()
    
    # Ã‰pocas
    print(f"\nğŸ”¢ Ã‰pocas (actual: {config['epochs']})")
    print("   Recomendado: 5-10 para pruebas, 25-50 para producciÃ³n")
    new_epochs = input(">>> Ã‰pocas: ").strip()
    if new_epochs:
        try:
            config['epochs'] = int(new_epochs)
        except ValueError:
            print("âš ï¸  Valor invÃ¡lido, manteniendo actual")
    
    # Batch size
    print(f"\nğŸ“¦ Batch Size (actual: {config['batch_size']})")
    print("   Recomendado: 8-16 para GPU con poca memoria, 32-64 para GPU potente")
    new_batch = input(">>> Batch size: ").strip()
    if new_batch:
        try:
            config['batch_size'] = int(new_batch)
        except ValueError:
            print("âš ï¸  Valor invÃ¡lido, manteniendo actual")
    
    # Learning rate
    print(f"\nğŸ“ˆ Learning Rate (actual: {config['learning_rate']})")
    print("   Recomendado: 0.001 estÃ¡ndar, 0.0001 para ajuste fino, 0.01 para convergencia rÃ¡pida")
    new_lr = input(">>> Learning rate: ").strip()
    if new_lr:
        try:
            config['learning_rate'] = float(new_lr)
        except ValueError:
            print("âš ï¸  Valor invÃ¡lido, manteniendo actual")
    
    # DuraciÃ³n de audio
    print(f"\nğŸµ DuraciÃ³n de audio en segundos (actual: {config['duration']})")
    print("   Recomendado: 3-10 segundos para balance tiempo/informaciÃ³n")
    print("   MÃNIMO: 2 segundos (duraciones menores causan errores)")
    new_duration = input(">>> DuraciÃ³n: ").strip()
    if new_duration:
        try:
            duration = float(new_duration)
            if duration < 1.0:
                print("âš ï¸  DuraciÃ³n demasiado corta, estableciendo mÃ­nimo de 2s")
                config['duration'] = 2.0
            else:
                config['duration'] = duration
        except ValueError:
            print("âš ï¸  Valor invÃ¡lido, manteniendo actual")
    
    # TamaÃ±o de muestra
    current_sample = config['sample_size'] or "Completo"
    print(f"\nğŸ¯ TamaÃ±o de muestra (actual: {current_sample})")
    print("   Ejemplos: 100 para pruebas rÃ¡pidas, 1000 para validaciÃ³n, vacÃ­o para dataset completo")
    new_sample = input(">>> TamaÃ±o muestra: ").strip()
    if new_sample:
        try:
            if new_sample.lower() in ["completo", "full", ""]:
                config['sample_size'] = None
            else:
                sample_size = int(new_sample)
                if sample_size < 50:
                    print("âš ï¸  Muestra muy pequeÃ±a, estableciendo mÃ­nimo de 50")
                    config['sample_size'] = 50
                else:
                    config['sample_size'] = sample_size
        except ValueError:
            print("âš ï¸  Valor invÃ¡lido, manteniendo actual")
    
    # Frecuencia de guardado
    print(f"\nğŸ’¾ Guardar checkpoint cada N Ã©pocas (actual: {config['save_every']})")
    print("   Recomendado: 5 para entrenamientos largos, 2-3 para monitoreo frecuente")
    new_save = input(">>> Frecuencia guardado: ").strip()
    if new_save:
        try:
            config['save_every'] = max(1, int(new_save))
        except ValueError:
            print("âš ï¸  Valor invÃ¡lido, manteniendo actual")
    
    # Dispositivo
    print(f"\nğŸ–¥ï¸  Dispositivo (actual: {config['device']})")
    print("   Opciones: auto (detectar automÃ¡ticamente), cpu, cuda")
    new_device = input(">>> Dispositivo: ").strip().lower()
    if new_device and new_device in ['auto', 'cpu', 'cuda']:
        config['device'] = new_device
    elif new_device:
        print("âš ï¸  Dispositivo invÃ¡lido, manteniendo actual")
    
    # Validar configuraciÃ³n
    warnings = validate_config(config)
    if warnings:
        print(f"\nâš ï¸  ADVERTENCIAS DE CONFIGURACIÃ“N:")
        for warning in warnings:
            print(f"   {warning}")
        
        fix_config = input("\nÂ¿Aplicar correcciones automÃ¡ticas? (Y/n): ").strip().lower()
        if fix_config != 'n':
            config = apply_auto_corrections(config)
    
    return config

def apply_auto_corrections(config):
    """Aplicar correcciones automÃ¡ticas a la configuraciÃ³n"""
    print("\nğŸ”§ Aplicando correcciones automÃ¡ticas...")
    
    # Corregir duraciÃ³n mÃ­nima
    if config['duration'] < 2.0:
        config['duration'] = 3.0
        print(f"   âœ… DuraciÃ³n corregida a {config['duration']}s")
    
    # Corregir batch size para GPU
    if config['device'] == 'cuda' and config['batch_size'] > 128:
        config['batch_size'] = 32
        print(f"   âœ… Batch size corregido a {config['batch_size']}")
    
    # Corregir learning rate
    if config['learning_rate'] > 0.01:
        config['learning_rate'] = 0.001
        print(f"   âœ… Learning rate corregido a {config['learning_rate']}")
    elif config['learning_rate'] < 1e-5:
        config['learning_rate'] = 1e-4
        print(f"   âœ… Learning rate corregido a {config['learning_rate']}")
    
    # Corregir Ã©pocas vs muestra
    if config['sample_size'] and config['sample_size'] < 1000 and config['epochs'] > 20:
        config['epochs'] = 10
        print(f"   âœ… Ã‰pocas corregidas a {config['epochs']} para muestra pequeÃ±a")
    
    return config

def handle_checkpoints(models, checkpoints):
    """Manejar checkpoints existentes"""
    if not checkpoints:
        return False, []
    
    # Filtrar checkpoints de modelos seleccionados
    relevant_checkpoints = {k: v for k, v in checkpoints.items() if k in models}
    
    if not relevant_checkpoints:
        return False, []
    
    print("\nğŸ”„ CHECKPOINTS DETECTADOS")
    print("="*40)
    for model, info in relevant_checkpoints.items():
        print(f"ğŸ“ {model}: Ã‰poca {info['epoch']} ({info['date']})")
    
    print("\nOpciones:")
    print("1. Continuar desde checkpoints")
    print("2. Empezar desde cero")
    print("3. Ver detalles de checkpoints")
    
    while True:
        choice = input(">>> OpciÃ³n (1-3): ").strip()
        
        if choice == "1":
            return True, relevant_checkpoints
        elif choice == "2":
            # Preguntar si eliminar checkpoints
            delete = input("Â¿Eliminar checkpoints existentes? (y/N): ").strip().lower()
            if delete == 'y':
                for info in relevant_checkpoints.values():
                    try:
                        info['path'].unlink()
                        print(f"ğŸ—‘ï¸  Eliminado: {info['file']}")
                    except:
                        pass
            return False, []
        elif choice == "3":
            show_checkpoint_details(relevant_checkpoints)
        else:
            print("âŒ OpciÃ³n no vÃ¡lida.")

def show_checkpoint_details(checkpoints):
    """Mostrar detalles de checkpoints"""
    print("\nğŸ“Š DETALLES DE CHECKPOINTS")
    print("="*50)
    
    for model, info in checkpoints.items():
        print(f"\nğŸ¯ {model.upper()}")
        print(f"   ğŸ“„ Archivo: {info['file']}")
        print(f"   ğŸ“… Fecha: {info['date']}")
        print(f"   ğŸ”¢ Ã‰poca: {info['epoch']}")
        print(f"   ğŸ“ Ruta: {info['path']}")
        
        # Intentar leer mÃ©tricas del checkpoint si es posible
        try:
            import torch
            checkpoint_data = torch.load(info['path'], map_location='cpu')
            if 'metrics' in checkpoint_data:
                metrics = checkpoint_data['metrics']
                if 'best_val_acc' in metrics:
                    print(f"   ğŸ¯ Mejor accuracy: {metrics['best_val_acc']:.2f}%")
        except:
            pass

def show_existing_results(results):
    """Mostrar resultados de modelos ya entrenados"""
    if not results:
        print("\nğŸ“Š No hay modelos entrenados previamente")
        return
    
    print("\nğŸ† MODELOS YA ENTRENADOS")
    print("="*50)
    
    # Ordenar por AUC
    sorted_results = sorted(results.items(), key=lambda x: x[1]['auc'], reverse=True)
    
    for model, info in sorted_results:
        print(f"\nğŸ¯ {model.upper()}")
        print(f"   ğŸ¯ Accuracy: {info['accuracy']:.2f}%")
        print(f"   ğŸ“ˆ AUC: {info['auc']:.3f}")
        print(f"   ğŸ“… Fecha: {info['date']}")

def estimate_time(models, config):
    """Estimar tiempo total de entrenamiento"""
    time_per_epoch = {
        'cnn1d': 10,
        'cnn2d': 15, 
        'resnet': 20,
        'lstm': 25,
        'gru': 20,
        'hybrid': 30
    }
    
    total_minutes = 0
    epochs = config['epochs']
    
    for model in models:
        if model in time_per_epoch:
            total_minutes += time_per_epoch[model] * epochs
    
    # Ajustar por tamaÃ±o de muestra
    if config['sample_size']:
        # Escalado aproximado
        factor = min(1.0, config['sample_size'] / 10000)
        total_minutes *= factor
    
    hours = total_minutes // 60
    minutes = total_minutes % 60
    
    return hours, minutes

def print_summary(models, config, use_checkpoints, time_estimate):
    """Mostrar resumen de la configuraciÃ³n"""
    print("\nğŸ“‹ RESUMEN DE CONFIGURACIÃ“N")
    print("="*50)
    
    # Modelos
    if models == ["eval-only"]:
        print("ğŸ¯ Modo: Solo evaluaciÃ³n")
    else:
        print(f"ğŸ¯ Modelos: {', '.join(models)}")
    
    # ConfiguraciÃ³n
    print(f"ğŸ”¢ Ã‰pocas: {config['epochs']}")
    print(f"ğŸ“¦ Batch size: {config['batch_size']}")
    print(f"ğŸ“ˆ Learning rate: {config['learning_rate']}")
    print(f"ğŸµ DuraciÃ³n audio: {config['duration']}s")
    
    sample_text = f"{config['sample_size']:,}" if config['sample_size'] else "Completo"
    print(f"ğŸ¯ TamaÃ±o muestra: {sample_text}")
    
    print(f"ğŸ’¾ Checkpoint cada: {config['save_every']} Ã©pocas")
    print(f"ğŸ–¥ï¸  Dispositivo: {config['device']}")
    
    # Checkpoints
    if use_checkpoints:
        print("ğŸ”„ Continuar desde checkpoints: SÃ­")
    
    # Tiempo estimado
    if models != ["eval-only"] and time_estimate[0] > 0 or time_estimate[1] > 0:
        if time_estimate[0] > 0:
            print(f"â±ï¸  Tiempo estimado: {time_estimate[0]}h {time_estimate[1]}min")
        else:
            print(f"â±ï¸  Tiempo estimado: {time_estimate[1]}min")

def build_command(models, config, use_checkpoints, checkpoints):
    """Construir comando de ejecuciÃ³n"""
    cmd = [sys.executable, "deep_learning_training.py"]
    
    # Modelos
    if models == ["eval-only"]:
        cmd.append("--eval-only")
    else:
        cmd.extend(["--models"] + models)
    
    # ConfiguraciÃ³n
    cmd.extend([
        "--epochs", str(config['epochs']),
        "--batch-size", str(config['batch_size']),
        "--learning-rate", str(config['learning_rate']),
        "--duration", str(config['duration']),
        "--save-every", str(config['save_every']),
        "--device", config['device']
    ])
    
    if config['sample_size']:
        cmd.extend(["--sample-size", str(config['sample_size'])])
    
    # AÃ±adir opciÃ³n para continuar desde checkpoints
    if use_checkpoints:
        cmd.append("--resume-from-checkpoints")
    
    # AÃ±adir estrategia de GPU si es relevante
    if torch.cuda.is_available():
        cmd.extend(["--gpu-strategy", "optimal"])
    
    return cmd

def main():
    """FunciÃ³n principal completamente interactiva"""
    
    print("ğŸµ SISTEMA INTERACTIVO DE DEEP LEARNING")
    print("="*60)
    print("ğŸ¤– ConfiguraciÃ³n automÃ¡tica y detecciÃ³n inteligente")
    
    # Mostrar informaciÃ³n de GPU
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        print(f"ğŸš€ GPUs detectadas: {gpu_count}")
        for i in range(gpu_count):
            gpu_name = torch.cuda.get_device_name(i)
            memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3
            print(f"   GPU {i}: {gpu_name} ({memory_gb:.1f}GB)")
    else:
        print("ğŸ”§ No hay GPU disponible - usando CPU")
    
    # Cargar configuraciÃ³n previa
    config = load_config()
    
    # Detectar estado actual
    print("\nğŸ” Detectando estado del sistema...")
    checkpoints = detect_checkpoints()
    existing_results = detect_existing_results()
    
    if checkpoints:
        print(f"âœ… Detectados {len(checkpoints)} checkpoints")
    if existing_results:
        print(f"âœ… Detectados {len(existing_results)} modelos entrenados")
    
    # Mostrar resultados existentes si los hay
    if existing_results:
        show_existing_results(existing_results)
    
    print("\n" + "="*60)
    
    # MenÃº principal
    while True:
        print("\nğŸ¯ Â¿QUÃ‰ QUIERES HACER?")
        print("1. ğŸš€ Entrenar modelo(s)")
        print("2. âš™ï¸  Configurar hiperparÃ¡metros")
        print("3. ğŸ“Š Solo evaluar modelos existentes")
        print("4. ğŸ—‘ï¸  Limpiar checkpoints/resultados")
        print("5. â“ Ayuda y ejemplos")
        print("0. ğŸšª Salir")
        
        choice = input("\n>>> OpciÃ³n: ").strip()
        
        if choice == "0":
            print("ğŸ‘‹ Â¡Hasta luego!")
            break
            
        elif choice == "1":
            # Entrenar modelos
            train_workflow(config, checkpoints, existing_results)
            break
            
        elif choice == "2":
            # Configurar hiperparÃ¡metros
            config = configure_hyperparameters(config)
            save_config(config)
            print("\nâœ… ConfiguraciÃ³n guardada")
            
        elif choice == "3":
            # Solo evaluaciÃ³n
            if existing_results:
                confirm = input("\nÂ¿Ejecutar evaluaciÃ³n de modelos existentes? (Y/n): ").strip().lower()
                if confirm != 'n':
                    run_evaluation()
                    break
            else:
                print("\nâŒ No hay modelos entrenados para evaluar")
                
        elif choice == "4":
            # Limpiar datos
            cleanup_menu(checkpoints, existing_results)
            # Redetectar despuÃ©s de limpieza
            checkpoints = detect_checkpoints()
            existing_results = detect_existing_results()
            
        elif choice == "5":
            # Ayuda
            show_help()
            
        else:
            print("âŒ OpciÃ³n no vÃ¡lida")

def train_workflow(config, checkpoints, existing_results):
    """Flujo completo de entrenamiento"""
    
    # 1. Seleccionar modelos
    print("\n" + "="*60)
    print("PASO 1: SELECCIÃ“N DE MODELOS")
    models = select_models()
    
    if models == ["eval-only"]:
        run_evaluation()
        return
    
    # 2. Configurar hiperparÃ¡metros
    print("\n" + "="*60)
    print("PASO 2: CONFIGURACIÃ“N")
    
    print(f"\nConfiguraciÃ³n actual:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    change_config = input("\nÂ¿Cambiar configuraciÃ³n? (y/N): ").strip().lower()
    if change_config == 'y':
        config = configure_hyperparameters(config)
        save_config(config)
    
    # 3. Manejar checkpoints
    print("\n" + "="*60)
    print("PASO 3: CHECKPOINTS")
    
    use_checkpoints = False
    relevant_checkpoints = {}
    
    if checkpoints:
        use_checkpoints, relevant_checkpoints = handle_checkpoints(models, checkpoints)
    else:
        print("â„¹ï¸  No hay checkpoints existentes. Empezando desde cero.")
    
    # 4. Estimar tiempo
    time_estimate = estimate_time(models, config)
    
    # 5. Mostrar resumen y confirmar
    print("\n" + "="*60)
    print("PASO 4: CONFIRMACIÃ“N")
    
    print_summary(models, config, use_checkpoints, time_estimate)
    
    # 6. Confirmar ejecuciÃ³n
    print("\nğŸ¯ Â¿PROCEDER CON EL ENTRENAMIENTO?")
    
    if time_estimate[0] > 2:  # MÃ¡s de 2 horas
        print("âš ï¸  ATENCIÃ“N: El entrenamiento tomarÃ¡ mucho tiempo")
        print("   RecomendaciÃ³n: Ejecutar en screen/tmux o usar muestra mÃ¡s pequeÃ±a")
    
    confirm = input("\nÂ¿Continuar? (Y/n): ").strip().lower()
    if confirm == 'n':
        print("âŒ Entrenamiento cancelado")
        return
    
    # 7. Ejecutar
    print("\n" + "="*60)
    print("ğŸš€ INICIANDO ENTRENAMIENTO")
    
    cmd = build_command(models, config, use_checkpoints, relevant_checkpoints)
    print(f"ğŸ“‹ Comando: {' '.join(cmd)}")
    
    # Mostrar tip para interrumpir
    print("\nğŸ’¡ TIPS:")
    print("   - Ctrl+C para interrumpir (guarda checkpoint automÃ¡tico)")
    print("   - Los checkpoints se guardan automÃ¡ticamente")
    print("   - Resultados se guardan en ../models/")
    
    input("\nPresiona Enter para comenzar...")
    
    try:
        subprocess.run(cmd)
    except KeyboardInterrupt:
        print("\nâš ï¸  Entrenamiento interrumpido por el usuario")

def cleanup_menu(checkpoints, existing_results):
    """MenÃº de limpieza"""
    print("\nğŸ—‘ï¸  LIMPIEZA DE DATOS")
    print("="*30)
    
    print("Â¿QuÃ© quieres limpiar?")
    print("1. Checkpoints")
    print("2. Resultados de modelos")
    print("3. Todo")
    print("0. Cancelar")
    
    choice = input("\n>>> OpciÃ³n: ").strip()
    
    if choice == "1" and checkpoints:
        cleanup_checkpoints(checkpoints)
    elif choice == "2" and existing_results:
        cleanup_results(existing_results)
    elif choice == "3":
        if checkpoints:
            cleanup_checkpoints(checkpoints)
        if existing_results:
            cleanup_results(existing_results)
        cleanup_config()
    elif choice == "0":
        return
    else:
        print("âŒ OpciÃ³n no vÃ¡lida o no hay datos para limpiar")

def cleanup_checkpoints(checkpoints):
    """Limpiar checkpoints"""
    print(f"\nğŸ—‘ï¸  Limpiando {len(checkpoints)} checkpoints...")
    
    for model, info in checkpoints.items():
        try:
            # Eliminar archivo de checkpoint
            info['path'].unlink()
            print(f"âœ… Eliminado checkpoint de {model}")
            
            # Eliminar directorio si estÃ¡ vacÃ­o
            if not any(info['path'].parent.iterdir()):
                info['path'].parent.rmdir()
                
        except Exception as e:
            print(f"âŒ Error eliminando {model}: {e}")

def cleanup_results(existing_results):
    """Limpiar resultados"""
    print(f"\nğŸ—‘ï¸  Limpiando {len(existing_results)} resultados...")
    
    results_dir = Path('../models')
    for model, info in existing_results.items():
        try:
            # Buscar y eliminar archivos relacionados
            pattern = f"{model}_*"
            for file_path in results_dir.glob(pattern):
                file_path.unlink()
                print(f"âœ… Eliminado {file_path.name}")
                
        except Exception as e:
            print(f"âŒ Error eliminando archivos de {model}: {e}")

def cleanup_config():
    """Limpiar configuraciÃ³n"""
    config_file = Path('dl_config.json')
    if config_file.exists():
        config_file.unlink()
        print("âœ… ConfiguraciÃ³n eliminada")

def run_evaluation():
    """Ejecutar solo evaluaciÃ³n"""
    cmd = [sys.executable, "deep_learning_training.py", "--eval-only"]
    print("ğŸ“Š Ejecutando evaluaciÃ³n de modelos existentes...")
    print(f"Comando: {' '.join(cmd)}")
    subprocess.run(cmd)

def show_help():
    """Mostrar ayuda detallada"""
    print("\nâ“ AYUDA DEL SISTEMA")
    print("="*50)
    
    print("\nğŸ¯ FLUJO TÃPICO:")
    print("1. Configurar hiperparÃ¡metros (una vez)")
    print("2. Seleccionar modelo(s) a entrenar") 
    print("3. El sistema detecta checkpoints automÃ¡ticamente")
    print("4. Elegir continuar o empezar desde cero")
    print("5. Revisar resumen y confirmar")
    print("6. Â¡Entrenar!")
    
    print("\nğŸ’¡ RECOMENDACIONES:")
    print("ğŸ”¸ Para pruebas: 1 modelo, muestra 100-500, 5 Ã©pocas")
    print("ğŸ”¸ Para validaciÃ³n: 2-3 modelos, muestra 1000, 15 Ã©pocas")
    print("ğŸ”¸ Para producciÃ³n: Todos modelos, dataset completo, 25-50 Ã©pocas")
    
    print("\nâš¡ OPTIMIZACIÃ“N:")
    print("ğŸ”¸ GPU recomendada para entrenamiento")
    print("ğŸ”¸ Usar batch_size mÃ¡s grande si tienes memoria GPU")
    print("ğŸ”¸ Los checkpoints permiten reanudar entrenamiento")
    
    print("\nğŸ“ ARCHIVOS GENERADOS:")
    print("ğŸ”¸ ../checkpoints/: Checkpoints por modelo")
    print("ğŸ”¸ ../models/: Modelos finales y resultados")
    print("ğŸ”¸ dl_config.json: Tu configuraciÃ³n guardada")
    
    print("\nğŸ†˜ SOLUCIÃ“N DE PROBLEMAS:")
    print("ğŸ”¸ Error de memoria: Reducir batch_size")
    print("ğŸ”¸ Entrenamiento lento: Usar GPU o muestra mÃ¡s pequeÃ±a")
    print("ğŸ”¸ Interrumpir: Ctrl+C (guarda checkpoint automÃ¡tico)")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Â¡Hasta luego!")
    except Exception as e:
        print(f"\nâŒ Error inesperado: {e}")
        print("ğŸ’¡ Intenta de nuevo o reporta el problema")
